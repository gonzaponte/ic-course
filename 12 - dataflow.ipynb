{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2c2cd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:38:29.875286Z",
     "start_time": "2024-04-09T10:38:29.863377Z"
    }
   },
   "outputs": [],
   "source": [
    "from invisible_cities.dataflow import dataflow as fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ba707",
   "metadata": {},
   "source": [
    "# Dataflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a541a",
   "metadata": {},
   "source": [
    "IC is based on a framework named `dataflow`. This is based on a pipeline workflow, in which a data stream can, for example be split into many, each performing a different task.\n",
    "\n",
    "In dataflow, a workflow is composed of three elements:\n",
    "- a source: provides the data downstream (e.g. reading from a file)\n",
    "- a pipe: transforms, filters and consumes the data\n",
    "- a result: the output of the workflow\n",
    "\n",
    "Pipes are composable object , i.e. they can contain many sub-pipes. They come in 3 flavours:\n",
    "- map (`fl.map`): applies a transformation to the data\n",
    "- filter (`fl.filter`): selects data based on some criteria\n",
    "- sink (`fl.sink`): consumes the data (doesn't propagate the data downstream)\n",
    "\n",
    "A workflow can be split into many using\n",
    "- branch (`fl.branch`): creates a separate workflow, but does not consume the data\n",
    "- fork (`fl.fork`): creates many separate workflows, consuming the data (i.e. a fork is a sink)\n",
    "  \n",
    "There are other utilities based on this concepts:\n",
    "- spy (`fl.spy`): meant for data inspection, without transformations (it does not guarantee it)\n",
    "- count (`fl.count`): counts events reaching the component\n",
    "\n",
    "Unfortunately, there isn't much documentation. You can find the definitions in\n",
    "\n",
    "https://github.com/next-exp/IC/blob/master/invisible_cities/dataflow/dataflow.py\n",
    "\n",
    "and usage examples in\n",
    "\n",
    "https://github.com/next-exp/IC/blob/master/invisible_cities/dataflow/dataflow_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b665c2",
   "metadata": {},
   "source": [
    "# City structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965020b",
   "metadata": {},
   "source": [
    "The default dataflow architecture assumes a single input object and a single output object. In IC, we need to handle many objects simultaneously (e.g. event number, time, kDST, hDST, ...) and each component may use only a subset of those. Moreover, the output of a component might need to be combined with others. This is why the data stream in IC is made of dictionaries. Each key in the dictionary contains a different object. For instance, the source for beersheba generates the following dictionary\n",
    "\n",
    "```\n",
    "dict(hits         = ...,\n",
    "     kdst         = ...,\n",
    "     run_number   = ...,\n",
    "     event_number = ...,\n",
    "     timestamp    = ...)\n",
    "```\n",
    "\n",
    "To restrict a pipe component to certain entries, we use the `args` argument. For instance\n",
    "\n",
    "```fl.map(a_function, args=\"kdst\")```\n",
    "\n",
    "if we only need one argument or\n",
    "\n",
    "```fl.map(a_function, args=(\"hits\", \"event_number\"))```\n",
    "\n",
    "if we need many.\n",
    "\n",
    "The output of the function follows a similar pattern. If we want to introduce the output in the data stream we use the `out` keyword:\n",
    "\n",
    "```fl.map(a_function, out=\"some_name\")```\n",
    "\n",
    "if we only have one output or\n",
    "\n",
    "```fl.map(a_function, out=(\"some_name\", \"some_other_name\"))```\n",
    "\n",
    "if we have many.\n",
    "\n",
    "Finally, if the output replaces the input, we can use\n",
    "\n",
    "```fl.map(a_function, args=\"something\", out=\"something\")```\n",
    "\n",
    "or simply\n",
    "\n",
    "```fl.map(a_function, item=\"something\")```\n",
    "\n",
    "Lastly, if in a given pipeline we only need one of those objects, we can narrow it down by placing the label in the pipeline like:\n",
    "\n",
    "```(\"hits\", a_function_that_processes_hits)```\n",
    "\n",
    "It must be noted that none of the components after the selection will be able to access the data in any of the other labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60317c94",
   "metadata": {},
   "source": [
    "# Some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8401b57",
   "metadata": {},
   "source": [
    "## Simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544bc860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:38:29.882946Z",
     "start_time": "2024-04-09T10:38:29.878073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "a_source  = range(10)\n",
    "collect   = []\n",
    "a_pipe    = fl.pipe( fl.map(lambda x: x**2)\n",
    "                   , fl.sink(collect.append)\n",
    "                   )\n",
    "fl.push( source = a_source\n",
    "       , pipe   = a_pipe)\n",
    "\n",
    "print(collect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634a393",
   "metadata": {},
   "source": [
    "## With a branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b8d1d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:38:29.892067Z",
     "start_time": "2024-04-09T10:38:29.885016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "a_source   = range(10)\n",
    "collect    = []\n",
    "collect_sq = []\n",
    "a_pipe     = fl.pipe( fl.branch(fl.sink(collect.append))\n",
    "                    , fl.map(lambda x: x**2)\n",
    "                    , fl.sink(collect_sq.append)\n",
    "                    )\n",
    "fl.push( source = a_source\n",
    "       , pipe   = a_pipe)\n",
    "\n",
    "print(collect)\n",
    "print(collect_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775222c5",
   "metadata": {},
   "source": [
    "## With a fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56e56fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:38:29.902557Z",
     "start_time": "2024-04-09T10:38:29.895433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n"
     ]
    }
   ],
   "source": [
    "a_source   = range(10)\n",
    "collect    = []\n",
    "collect_sq = []\n",
    "collect_cb = []\n",
    "a_pipe     = fl.pipe( fl.fork(                          fl.sink(collect   .append)\n",
    "                             , (fl.map(lambda x: x**2), fl.sink(collect_sq.append))\n",
    "                             , (fl.map(lambda x: x**3), fl.sink(collect_cb.append))\n",
    "                             )\n",
    "                    )\n",
    "fl.push( source = a_source\n",
    "       , pipe   = a_pipe)\n",
    "\n",
    "print(collect)\n",
    "print(collect_sq)\n",
    "print(collect_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48627fac",
   "metadata": {},
   "source": [
    "## Using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43187071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:38:29.913482Z",
     "start_time": "2024-04-09T10:38:29.905414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "a_source   = ({\"a\": i} for i in range(10))\n",
    "collect    = []\n",
    "collect_sq = []\n",
    "a_pipe     = fl.pipe( fl.map(lambda x: x**2, args=\"a\", out=\"b\")\n",
    "                    , fl.fork( fl.sink(collect   .append, args=\"a\")\n",
    "                             , fl.sink(collect_sq.append, args=\"b\"))\n",
    "                    )\n",
    "fl.push( source = a_source\n",
    "       , pipe   = a_pipe)\n",
    "\n",
    "print(collect)\n",
    "print(collect_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02636e6",
   "metadata": {},
   "source": [
    "# Exploring detsim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2cb5c",
   "metadata": {},
   "source": [
    "```python\n",
    "fl.push(source = MC_hits_from_files(files_in, rate),               # reads data from file\n",
    "        pipe   = fl.pipe( fl.slice(*event_range, close_all=True)   # selects events based on configuration\n",
    "                        , filter_delayed_hits\n",
    "                        , select_s1_candidate_hits\n",
    "                        , select_active_hits\n",
    "                        , filter_events_no_active_hits\n",
    "                        , fl.branch(write_nohits_filter)           # a separate workflow that simply writes the outcome of the filter to file\n",
    "                        , events_passed_active_hits.filter         # the actual event filter\n",
    "                        , simulate_electrons\n",
    "                        , count_photons\n",
    "                        , fl.branch(write_dark_evt_filter)         # another filter\n",
    "                        , dark_events.filter\n",
    "                        , get_buffer_times_and_length\n",
    "                        , create_pmt_waveforms\n",
    "                        , create_sipm_waveforms\n",
    "                        , get_bin_edges\n",
    "                        , buffer_calculation\n",
    "                        , \"event_number\"                           # keeps only the event number for the remainder of the pipeline\n",
    "                        , evtnum_collect.sink),                    # collects event numbers using a sink\n",
    "        result  = dict( events_in     = event_count_in.future\n",
    "                      , evtnum_list   = evtnum_collect.future\n",
    "                      , dark_events   = dark_events   .future))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
